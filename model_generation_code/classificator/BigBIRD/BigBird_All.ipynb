{"cells":[{"cell_type":"markdown","metadata":{"id":"Nf8D-EWWnaK3"},"source":["# Big Bird Classifier for all"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ldWe5M-dnfr0"},"outputs":[],"source":["!pip install datasets --quiet\n","!pip install transformers --quiet\n","!pip install torch --quiet\n","!pip install sentencepiece --quiet\n","!pip install --upgrade accelerate --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpmHASfKngX8"},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","from tqdm import tqdm\n","import warnings\n","import os\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4391,"status":"ok","timestamp":1684344604905,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"},"user_tz":-120},"id":"axBsCl59nuyO","outputId":"88d52c83-80c0-4862-837f-395db40f6276"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/Shareddrives/DL + NLP/Proyecto DL + NLP/Entrega_Final/data/raw"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUbO5vVBOaj8","executionInfo":{"status":"ok","timestamp":1684344604906,"user_tz":-120,"elapsed":7,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"2479cc18-afd8-4949-e5cc-bf0a232b4ed1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1j0RASnE3IntTbVJIRuwXAvt885-X9BEv/Proyecto DL + NLP/Entrega_Final/data/raw\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1684344604906,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"},"user_tz":-120},"id":"Bn7wY_pPoAc9","outputId":"bce0ccdc-df34-41b4-cb33-3a54c2367064"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mADHD\u001b[0m/     \u001b[01;34mBPD\u001b[0m/                   \u001b[01;34mDATASET_CONTROL\u001b[0m/  \u001b[01;34mPTSD\u001b[0m/\n","\u001b[01;34mAnxiety\u001b[0m/  combined_balanced.csv  \u001b[01;34mDepression\u001b[0m/       \u001b[01;34mSchizophrenia\u001b[0m/\n","\u001b[01;34mBipolar\u001b[0m/  combined.csv           \u001b[01;34mEDA\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CeB1wcTKo0bI"},"outputs":[],"source":["data = pd.read_csv('./combined_balanced.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1684344605690,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"},"user_tz":-120},"id":"eTuoqBo3o31u","outputId":"23166f76-dd1a-4ead-b469-28981d7147e8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            subreddit                                               post  \\\n","0             control  What do you do when most of a class passes and...   \n","1             control  Picking a chapter book for \"cool down time\" I'...   \n","2             control  How can I prevent alumni from visiting me? As ...   \n","3             control  Why I feel like a dumb student In elementary S...   \n","4             control  Anonymous questionnaire on Social Anxiety Hell...   \n","...               ...                                                ...   \n","143995  bipolarreddit  Business travel w/ bipolar? Hi Friends -\\n\\nI'...   \n","143996  bipolarreddit  Finding a job when depressed is impossible. Fi...   \n","143997  bipolarreddit  Mania?? I was diagnosed with bipolar over 4 ye...   \n","143998  bipolarreddit  Are any of you successfully managing your cond...   \n","143999  bipolarreddit  My job has become too much. What do I do next?...   \n","\n","        label  \n","0           0  \n","1           0  \n","2           0  \n","3           0  \n","4           0  \n","...       ...  \n","143995      3  \n","143996      3  \n","143997      3  \n","143998      3  \n","143999      3  \n","\n","[144000 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-b2b94dc6-3857-4fb6-bd3b-cd3fea84636d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>subreddit</th>\n","      <th>post</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>control</td>\n","      <td>What do you do when most of a class passes and...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>control</td>\n","      <td>Picking a chapter book for \"cool down time\" I'...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>control</td>\n","      <td>How can I prevent alumni from visiting me? As ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>control</td>\n","      <td>Why I feel like a dumb student In elementary S...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>control</td>\n","      <td>Anonymous questionnaire on Social Anxiety Hell...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>143995</th>\n","      <td>bipolarreddit</td>\n","      <td>Business travel w/ bipolar? Hi Friends -\\n\\nI'...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>143996</th>\n","      <td>bipolarreddit</td>\n","      <td>Finding a job when depressed is impossible. Fi...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>143997</th>\n","      <td>bipolarreddit</td>\n","      <td>Mania?? I was diagnosed with bipolar over 4 ye...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>143998</th>\n","      <td>bipolarreddit</td>\n","      <td>Are any of you successfully managing your cond...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>143999</th>\n","      <td>bipolarreddit</td>\n","      <td>My job has become too much. What do I do next?...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>144000 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2b94dc6-3857-4fb6-bd3b-cd3fea84636d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b2b94dc6-3857-4fb6-bd3b-cd3fea84636d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b2b94dc6-3857-4fb6-bd3b-cd3fea84636d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["data"]},{"cell_type":"code","source":["data['subreddit'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sMQayKcRTSH2","executionInfo":{"status":"ok","timestamp":1684344605690,"user_tz":-120,"elapsed":8,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"7bd9894f-fb0c-464e-d60e-4aedce7a3fa6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['control', 'depression', 'anxiety', 'adhd', 'bpd', 'EDAnonymous',\n","       'schizophrenia', 'ptsd', 'bipolarreddit'], dtype=object)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["data['subreddit'] = data['subreddit'].str.replace('EDAnonymous','eda')\n","data['subreddit'] = data['subreddit'].str.replace('bipolarreddit','bipolar')"],"metadata":{"id":"Z0jq-hkMThUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['subreddit'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1OAzYzohTtRd","executionInfo":{"status":"ok","timestamp":1684344605691,"user_tz":-120,"elapsed":7,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"fdd39dee-7def-42bc-e2ab-f9793141121e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['control', 'depression', 'anxiety', 'adhd', 'bpd', 'eda',\n","       'schizophrenia', 'ptsd', 'bipolar'], dtype=object)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I0STRn9xqCDn"},"outputs":[],"source":["train_text_df  = data.rename(columns={'subreddit': 'entities', 'post': 'text', 'label': 'labels'})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZ8BdZD8qg2t"},"outputs":[],"source":["train_text_df [\"id\"] = train_text_df .index + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFMwtbmirZyN"},"outputs":[],"source":["train_text_df ['entities'] = train_text_df ['entities'].str.strip('()').str.split(',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mTfzWpz7sSHw"},"outputs":[],"source":["from sklearn.utils import shuffle\n","train_text_df = shuffle(train_text_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdLGW0VZLo9O"},"outputs":[],"source":["train_text_df.drop(['labels'], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6hFqvdQMCwB"},"outputs":[],"source":["train_text_df = train_text_df.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1684344606978,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"},"user_tz":-120},"id":"Ehdp83Swqj7Q","outputId":"82036908-a8d2-4e87-c7b9-5c69cbb8072c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            entities                                               text  \\\n","0       [depression]  How do I hide my depression? It's making my da...   \n","1             [ptsd]  Feeling the need to reach out to abuser during...   \n","2          [bipolar]  Inspired by the other post: lamictal solo trea...   \n","3          [anxiety]  First anxiety attack Always struggled with anx...   \n","4          [bipolar]  Here comes the mania! It's nearly 1am. I have ...   \n","...              ...                                                ...   \n","143995        [ptsd]  Ocular migraine. The fuck. Y’all doing this to...   \n","143996     [bipolar]  Going through divorce and I don't care is this...   \n","143997         [eda]  Peach is reaching out for someone to adopt and...   \n","143998        [adhd]  First thing in the morning Do any of you lovel...   \n","143999         [eda]  I want a version of wintergirls from cassies p...   \n","\n","            id  \n","0        18455  \n","1       125564  \n","2       133794  \n","3        47085  \n","4       129229  \n","...        ...  \n","143995  127576  \n","143996  142672  \n","143997   86518  \n","143998   48313  \n","143999   94904  \n","\n","[144000 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-84850499-66b7-45cd-9239-9e0ed830bd6b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>entities</th>\n","      <th>text</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[depression]</td>\n","      <td>How do I hide my depression? It's making my da...</td>\n","      <td>18455</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[ptsd]</td>\n","      <td>Feeling the need to reach out to abuser during...</td>\n","      <td>125564</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[bipolar]</td>\n","      <td>Inspired by the other post: lamictal solo trea...</td>\n","      <td>133794</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[anxiety]</td>\n","      <td>First anxiety attack Always struggled with anx...</td>\n","      <td>47085</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[bipolar]</td>\n","      <td>Here comes the mania! It's nearly 1am. I have ...</td>\n","      <td>129229</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>143995</th>\n","      <td>[ptsd]</td>\n","      <td>Ocular migraine. The fuck. Y’all doing this to...</td>\n","      <td>127576</td>\n","    </tr>\n","    <tr>\n","      <th>143996</th>\n","      <td>[bipolar]</td>\n","      <td>Going through divorce and I don't care is this...</td>\n","      <td>142672</td>\n","    </tr>\n","    <tr>\n","      <th>143997</th>\n","      <td>[eda]</td>\n","      <td>Peach is reaching out for someone to adopt and...</td>\n","      <td>86518</td>\n","    </tr>\n","    <tr>\n","      <th>143998</th>\n","      <td>[adhd]</td>\n","      <td>First thing in the morning Do any of you lovel...</td>\n","      <td>48313</td>\n","    </tr>\n","    <tr>\n","      <th>143999</th>\n","      <td>[eda]</td>\n","      <td>I want a version of wintergirls from cassies p...</td>\n","      <td>94904</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>144000 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84850499-66b7-45cd-9239-9e0ed830bd6b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-84850499-66b7-45cd-9239-9e0ed830bd6b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-84850499-66b7-45cd-9239-9e0ed830bd6b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}],"source":["train_text_df "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":874,"status":"ok","timestamp":1684344607848,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"},"user_tz":-120},"id":"td4UONPxqkmb","outputId":"b56ee32b-43c4-4cc3-d451-3b2d7e776bc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["['depression']\n"]}],"source":["import ast\n","\n","train_text_df['entities'] = train_text_df['entities'].apply(lambda x:ast.literal_eval(str(x)))\n","\n","print(train_text_df['entities'].values[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLgDtX5xsCHx"},"outputs":[],"source":["train_text_df = train_text_df[:]"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"YbuhMrxjMQOz","colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1684943000881,"user_tz":-120,"elapsed":8,"user":{"displayName":"Unai Sainz Lugarezaresti","userId":"08290277786887764205"}},"outputId":"2442567f-6472-4352-ba93-ef0c4390403b"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-b6c64783d4c4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBigBirdForTokenClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBigBirdTokenizerFast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import datasets\n","from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n","from transformers import BigBirdForTokenClassification, BigBirdTokenizerFast\n","from torch import cuda\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPbK5KuiMQcJ"},"outputs":[],"source":["config = {'model_name': 'google/bigbird-roberta-base',\n","         'max_length': 150,\n","         'train_batch_size':4,\n","         'valid_batch_size':4,\n","         'epochs':5,\n","         'learning_rate':5e-05,\n","         'max_grad_norm':10,\n","          'warmup':0.1,\n","          \"grad_acc\":8,\n","          \"model_save_path\":\"big-bird\",\n","         'device': 'cuda' if cuda.is_available() else 'cpu'}\n","\n","output_labels = ['control', 'depression', 'anxiety', 'adhd', 'bpd', 'eda',\n","       'schizophrenia', 'ptsd', 'bipolar']\n","\n","labels_to_ids = {v:k for k,v in enumerate(output_labels)}\n","ids_to_labels = {k:v for k,v in enumerate(output_labels)}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1c3Qbv4eMhF8"},"outputs":[],"source":["train_text_df['labels'] = train_text_df['entities'].apply(lambda x: [labels_to_ids[i] for i in x])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684344614647,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"},"user_tz":-120},"id":"6AeX3AdkMocU","outputId":"eed998c5-9889-4403-8cc0-ef9a02a0d67d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       entities                                               text      id  \\\n","0  [depression]  How do I hide my depression? It's making my da...   18455   \n","1        [ptsd]  Feeling the need to reach out to abuser during...  125564   \n","2     [bipolar]  Inspired by the other post: lamictal solo trea...  133794   \n","3     [anxiety]  First anxiety attack Always struggled with anx...   47085   \n","4     [bipolar]  Here comes the mania! It's nearly 1am. I have ...  129229   \n","\n","  labels  \n","0    [1]  \n","1    [7]  \n","2    [8]  \n","3    [2]  \n","4    [8]  "],"text/html":["\n","  <div id=\"df-fce31d61-782f-4ac0-bd5e-0c95405ce16b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>entities</th>\n","      <th>text</th>\n","      <th>id</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[depression]</td>\n","      <td>How do I hide my depression? It's making my da...</td>\n","      <td>18455</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[ptsd]</td>\n","      <td>Feeling the need to reach out to abuser during...</td>\n","      <td>125564</td>\n","      <td>[7]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[bipolar]</td>\n","      <td>Inspired by the other post: lamictal solo trea...</td>\n","      <td>133794</td>\n","      <td>[8]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[anxiety]</td>\n","      <td>First anxiety attack Always struggled with anx...</td>\n","      <td>47085</td>\n","      <td>[2]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[bipolar]</td>\n","      <td>Here comes the mania! It's nearly 1am. I have ...</td>\n","      <td>129229</td>\n","      <td>[8]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fce31d61-782f-4ac0-bd5e-0c95405ce16b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fce31d61-782f-4ac0-bd5e-0c95405ce16b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fce31d61-782f-4ac0-bd5e-0c95405ce16b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}],"source":["train_text_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8G3rQTnMqts","executionInfo":{"status":"ok","timestamp":1684344618537,"user_tz":-120,"elapsed":3894,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"b23c546f-a173-41cb-8cf6-c26e534fd34b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["tokenizer = BigBirdTokenizerFast.from_pretrained(config['model_name'])\n","model = BigBirdForTokenClassification.from_pretrained(config['model_name'],\n","                                                     num_labels=len(output_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elS1-LYyMtXZ"},"outputs":[],"source":["converted = tokenizer(train_text_df.loc[0].values[1].split(),\n","                      is_split_into_words=True, return_offsets_mapping=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HdrYnbP2Mwf5","executionInfo":{"status":"ok","timestamp":1684344618538,"user_tz":-120,"elapsed":6,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"e2fe5db5-5f28-476a-8e66-bcaec0ebe2f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] (0, 0)\n","▁How (0, 3)\n","▁do (0, 2)\n","▁I (0, 1)\n","▁hide (0, 4)\n","▁my (0, 2)\n","▁depression (0, 10)\n","? (10, 11)\n","▁It (0, 2)\n","'s (2, 4)\n","▁making (0, 6)\n","▁my (0, 2)\n","▁dad (0, 3)\n","▁loose (0, 5)\n","▁his (0, 3)\n"]}],"source":["ix = 0\n","for i,j in zip(tokenizer.convert_ids_to_tokens(converted['input_ids']), converted['offset_mapping']):\n","    print(i, j)\n","    ix += 1\n","    if ix == 15:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WyfWcoQoMypo"},"outputs":[],"source":["def tokenizer_data(example):\n","    encoding = tokenizer(example['text'].split(),\n","                         is_split_into_words=True,\n","                         truncation=True,\n","                         padding='max_length', \n","                         return_offsets_mapping=True,\n","                         max_length=config['max_length'])\n","    i = 0\n","    labels = example['labels']\n","    encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","    for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","        if mapping[0] == 0 and mapping[1] != 0:\n","            try:\n","                encoded_labels[idx] = labels[i]\n","            except:\n","                pass\n","            i += 1\n","    item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","    item['labels'] = torch.as_tensor(encoded_labels)\n","    return item"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Evs1LJdaM1TL"},"outputs":[],"source":["dataset = datasets.Dataset.from_pandas(train_text_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OV7o6pTcM4W3","executionInfo":{"status":"ok","timestamp":1684344618946,"user_tz":-120,"elapsed":13,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"91bd271a-7390-48ab-a97f-2e8fa2791a26"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['entities', 'text', 'id', 'labels'],\n","        num_rows: 129600\n","    })\n","    test: Dataset({\n","        features: ['entities', 'text', 'id', 'labels'],\n","        num_rows: 14400\n","    })\n","})"]},"metadata":{},"execution_count":29}],"source":["dataset = dataset.train_test_split(test_size=0.1)\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZO-HtukIM6MT"},"outputs":[],"source":["text = dataset['train'][1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-O4z-BaM9O_","executionInfo":{"status":"ok","timestamp":1684344618946,"user_tz":-120,"elapsed":12,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"561b2b13-a34b-4cf9-eb9f-7fda95040852"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([   65, 18731,  3799,  2852,   477, 11363,  5458, 19370, 18595,  1159,\n","           116,   321,   100, 48515,   578,   415,   100,   404,   688,  1905,\n","           419,  2212,   385,  4584,   618,   112,   391,  6552,   415,  1355,\n","           624,  2014,   391,  3150,   112,   391,   508,   689,   415,   100,\n","           177,  1117,   385,  9908,   494, 11596,   388,  2164,  1242,   717,\n","         27298, 42355,   114,  2430,  2328,   385, 10749,   391,  3859,   718,\n","          1527, 11466,   385,   446,   578,   112,  6512,  4304,   529,  2158,\n","           113,   372,   113, 25903,  1618,  2010,   114,   871,  3232,  2669,\n","           115, 41503,   419,   365,  2339,  3722, 50348,   126,   136, 20780,\n","            66,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0]),\n"," 'offset_mapping': tensor([[ 0,  0],\n","         [ 0,  2],\n","         [ 2,  4],\n","         [ 4,  7],\n","         [ 0,  1],\n","         [ 1,  4],\n","         [ 0,  3],\n","         [ 0,  3],\n","         [ 3,  6],\n","         [ 0,  1],\n","         [ 1,  2],\n","         [ 0,  1],\n","         [ 0,  2],\n","         [ 0,  9],\n","         [ 0,  3],\n","         [ 0,  1],\n","         [ 1,  2],\n","         [ 2,  4],\n","         [ 0,  4],\n","         [ 0,  5],\n","         [ 0,  2],\n","         [ 0,  6],\n","         [ 0,  2],\n","         [ 0,  3],\n","         [ 0,  4],\n","         [ 4,  5],\n","         [ 0,  3],\n","         [ 0,  8],\n","         [ 0,  1],\n","         [ 0,  4],\n","         [ 0,  2],\n","         [ 0,  6],\n","         [ 0,  3],\n","         [ 0,  4],\n","         [ 4,  5],\n","         [ 0,  3],\n","         [ 0,  3],\n","         [ 0,  4],\n","         [ 0,  1],\n","         [ 1,  2],\n","         [ 2,  3],\n","         [ 0,  5],\n","         [ 0,  2],\n","         [ 0,  8],\n","         [ 0,  2],\n","         [ 0,  4],\n","         [ 0,  2],\n","         [ 0,  4],\n","         [ 0,  6],\n","         [ 0,  2],\n","         [ 0,  8],\n","         [ 0,  4],\n","         [ 4,  5],\n","         [ 0,  4],\n","         [ 0,  6],\n","         [ 0,  2],\n","         [ 0,  9],\n","         [ 0,  3],\n","         [ 0,  4],\n","         [ 0,  4],\n","         [ 0,  3],\n","         [ 3, 10],\n","         [ 0,  2],\n","         [ 0,  3],\n","         [ 0,  3],\n","         [ 3,  4],\n","         [ 0,  9],\n","         [ 0,  7],\n","         [ 0,  4],\n","         [ 0,  4],\n","         [ 4,  5],\n","         [ 5,  7],\n","         [ 7,  8],\n","         [ 8, 12],\n","         [ 0,  5],\n","         [ 0,  5],\n","         [ 5,  6],\n","         [ 0,  4],\n","         [ 0,  5],\n","         [ 0,  6],\n","         [ 6,  7],\n","         [ 7, 15],\n","         [ 0,  2],\n","         [ 0,  1],\n","         [ 1,  3],\n","         [ 0,  4],\n","         [ 0,  2],\n","         [ 2,  3],\n","         [ 3,  4],\n","         [ 4,  6],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0],\n","         [ 0,  0]]),\n"," 'labels': tensor([-100,    5, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100])}"]},"metadata":{},"execution_count":31}],"source":["converted = tokenizer_data(text)\n","\n","converted"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cs9G1lR6NA9A","executionInfo":{"status":"ok","timestamp":1684344618947,"user_tz":-120,"elapsed":11,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"b33ce7df-eef2-46ff-fe8c-5edb848da30a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] tensor(-100) tensor([0, 0])\n","▁FE tensor(5) tensor([0, 2])\n","EL tensor(-100) tensor([2, 4])\n","ING tensor(-100) tensor([4, 7])\n","▁F tensor(-100) tensor([0, 1])\n","AST tensor(-100) tensor([1, 4])\n","▁AND tensor(-100) tensor([0, 3])\n","▁STR tensor(-100) tensor([0, 3])\n","ONG tensor(-100) tensor([3, 6])\n","▁: tensor(-100) tensor([0, 1])\n","0 tensor(-100) tensor([1, 2])\n","▁ tensor(-100) tensor([0, 1])\n","<unk> tensor(-100) tensor([0, 2])\n","▁Literally tensor(-100) tensor([0, 9])\n","▁all tensor(-100) tensor([0, 3])\n"]}],"source":["converted\n","\n","i=0\n","for token, label in zip(tokenizer.convert_ids_to_tokens(converted[\"input_ids\"]), \n","                        converted[\"labels\"]):\n","    print(token, label, converted['offset_mapping'][i])\n","    i+=1\n","    if i == 15:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191,"referenced_widgets":["21a961e6a57b48bca7fbf892054b0eb7","5f7764561fb8445b8a39229ded586b6c","e7806248182f4e2caa9cf8ff5c034f93","9fc1fd6ccf2746079a0446f2beb7254e","b3fd4866ecb942449d8961fea43e4f94","0dd7fd83360d45a0bf19f75a1a140244","b221c5560eb9429d95e9524c47e755dd","d7cedd7072ab4c49b84d5a1c927bd4b2","3e3fcc2f0bd64a4a8462b2170ea490d3","ba7c0844a7a6480eb5d2db8817fcf4a4","67edd10eef1f4938ae9a260bec02c3e2","ee7770089fc44eaeb10bdf4db794a9d8","892c163accb84359b343687b276ba425","ce4ae6cbc76d4ee2a5400bf1aa66f56a","08b2ce73e42549af823274f29729e432","b3f6cada52bd46b9a4d98d1c5af5424a","efe3d8da1c934bc190d5e8cb039b9562","0583353c5ec549869f9bcc9e591837c3","68f22214ecd048b092c6ef6b6c91bef6","7133e40b2045404189000c6cd3265378","e5e11399e4c948379b261a07b62a9a63","3f2c07327f284388b65b34fd830eddf3"]},"id":"EeDoyhubNCwz","executionInfo":{"status":"ok","timestamp":1684345027242,"user_tz":-120,"elapsed":408301,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"0cb01564-a757-487d-a1ff-cc883aa5dbed"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/129600 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21a961e6a57b48bca7fbf892054b0eb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/14400 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee7770089fc44eaeb10bdf4db794a9d8"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['entities', 'text', 'id', 'labels', 'input_ids', 'attention_mask', 'offset_mapping'],\n","        num_rows: 129600\n","    })\n","    test: Dataset({\n","        features: ['entities', 'text', 'id', 'labels', 'input_ids', 'attention_mask', 'offset_mapping'],\n","        num_rows: 14400\n","    })\n","})"]},"metadata":{},"execution_count":33}],"source":["dataset = dataset.map(tokenizer_data)\n","\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXl5nNXwNEfN","executionInfo":{"status":"ok","timestamp":1684345027243,"user_tz":-120,"elapsed":14,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"52a3814b-23a6-4268-9251-7a8cec6360e9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['entities', 'text', 'id', 'labels', 'input_ids', 'attention_mask', 'offset_mapping'],\n","        num_rows: 129600\n","    })\n","    test: Dataset({\n","        features: ['entities', 'text', 'id', 'labels', 'input_ids', 'attention_mask', 'offset_mapping'],\n","        num_rows: 14400\n","    })\n","})"]},"metadata":{},"execution_count":34}],"source":["dataset.set_format(type='torch', columns=['input_ids', 'attention_mask',\n","                                         'labels'])\n","\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y33EHYntNHYc"},"outputs":[],"source":["for a in dataset['train']:\n","    if a['input_ids'].shape[0] != a['attention_mask'].shape[0]:\n","        print(a)\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jI6Au7hXNJsf"},"outputs":[],"source":["trainer_args = TrainingArguments(report_to='none',\n","                                output_dir=\"../../output/classificator/BigBird/All\",\n","                                num_train_epochs=config['epochs'],\n","                                evaluation_strategy ='epoch',\n","                                per_device_train_batch_size=config['train_batch_size'],\n","                                per_device_eval_batch_size=config['valid_batch_size'],\n","                                fp16=True,\n","                                save_strategy = \"epoch\",\n","                                warmup_ratio= config['warmup'],\n","                                gradient_accumulation_steps=config['grad_acc'],\n","                                logging_strategy=\"epoch\",\n","                                save_total_limit=1\n","                                )\n","\n","trainer = Trainer(model=model,\n","                  args=trainer_args, \n","                  train_dataset = dataset['train'],\n","                  eval_dataset=dataset['test'],\n","                  tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sr_Psei2pCaX","executionInfo":{"status":"error","timestamp":1684349992335,"user_tz":-120,"elapsed":1954733,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0b105e09-a9ef-4a18-c2a1-abe498a512e8"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["You're using a BigBirdTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Attention type 'block_sparse' is not possible if sequence_length: 150 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4886' max='20250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 4886/20250 49:21 < 2:35:15, 1.65 it/s, Epoch 1.21/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.738400</td>\n","      <td>0.486419</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='8134' max='20250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 8134/20250 1:21:55 < 2:02:03, 1.65 it/s, Epoch 2.01/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.738400</td>\n","      <td>0.486419</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.405300</td>\n","      <td>0.408280</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1664\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1662 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1664 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1666 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1667 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1940\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1937 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m model.no_sync():                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1938 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1939 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1940 \u001b[2m│   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1941 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1942 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1943 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2745\u001b[0m in \u001b[92mtraining_step\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2742 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = loss / \u001b[96mself\u001b[0m.args.gradient_accumulation_steps                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2743 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2744 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.do_grad_scaling:                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2745 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.scaler.scale(loss).backward()                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2746 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.use_apex:                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2747 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m amp.scale_loss(loss, \u001b[96mself\u001b[0m.optimizer) \u001b[94mas\u001b[0m scaled_loss:                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2748 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mscaled_loss.backward()                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1664</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1661 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1662 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1663 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1664 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1665 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1666 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1667 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1940</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> model.no_sync():                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1938 │   │   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1940 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 │   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1942 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1943 │   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2745</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2742 │   │   │   </span>loss = loss / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.gradient_accumulation_steps                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2743 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2744 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.do_grad_scaling:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2745 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.scale(loss).backward()                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2746 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.use_apex:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2747 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> amp.scale_loss(loss, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> scaled_loss:                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2748 │   │   │   │   </span>scaled_loss.backward()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 │   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 │   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   # The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   # some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   # calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 │   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"]},"metadata":{}}],"source":["#trainer.train()"]},{"cell_type":"code","source":["trainer.train(\"../../output/classificator/BigBird/All/checkpoint-16200\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"TqwFgM4L0gqd","executionInfo":{"status":"ok","timestamp":1684357647533,"user_tz":-120,"elapsed":2478792,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"outputId":"9eecdf7a-db3c-4a99-b3a5-77d5aabdb506"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='20250' max='20250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [20250/20250 41:10, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>5</td>\n","      <td>0.072700</td>\n","      <td>0.440286</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=20250, training_loss=0.014547444661458334, metrics={'train_runtime': 2470.9977, 'train_samples_per_second': 262.242, 'train_steps_per_second': 8.195, 'total_flos': 5.0922897855786e+16, 'train_loss': 0.014547444661458334, 'epoch': 5.0})"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QkLyxTXhNOcs"},"outputs":[],"source":["device = config['device']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-HKtiDIxNTBc"},"outputs":[],"source":["trainer.model.eval()\n","def inference(sentence):\n","    inputs = tokenizer(sentence.split(),\n","                        is_split_into_words=True, \n","                        return_offsets_mapping=True, \n","                        padding='max_length', \n","                        truncation=True, \n","                        max_length=200,\n","                        return_tensors=\"pt\")\n","\n","    # move to gpu\n","    ids = inputs[\"input_ids\"].to(device)\n","    mask = inputs[\"attention_mask\"].to(device)\n","    # forward pass\n","    outputs = trainer.model(input_ids=ids, attention_mask=mask, return_dict=False)\n","#     print(outputs)\n","    logits = outputs[0]\n","    \n","    active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","    flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n","    print(logits.shape, active_logits.shape, flattened_predictions.shape)\n","    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n","    token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n","    wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n","\n","    prediction = []\n","    out_str = []\n","    off_list = inputs[\"offset_mapping\"].squeeze().tolist()\n","    for idx, mapping in enumerate(off_list):\n","#         print(mapping, token_pred[1], token_pred[0],\"####\")\n","\n","#         only predictions on first word pieces are important\n","        if mapping[0] == 0 and mapping[1] != 0:\n","#             print(mapping, token_pred[1], token_pred[0])\n","            prediction.append(wp_preds[idx][1])\n","            out_str.append(wp_preds[idx][0])\n","        else:\n","            if idx == 1:\n","                prediction.append(wp_preds[idx][1])\n","                out_str.append(wp_preds[idx][0])\n","            continue\n","    return prediction, out_str"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bwps44GVh1Rg","executionInfo":{"status":"ok","timestamp":1684357679943,"user_tz":-120,"elapsed":746,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"609cd672-889c-4328-ab05-00e0093310b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 200, 9]) torch.Size([200, 9]) torch.Size([200])\n","anxiety\n"]}],"source":["#Anxiety\n","text_1= 'Ive never taken it to a doctor, but Ive heard that it could help for this problem, but I dont want to take it to the point where I am constantly afraid of dying.'\n","pred_1, _ = inference(text_1)\n","print(pred_1[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VK1bh3UPc5Kr","executionInfo":{"status":"ok","timestamp":1684357689362,"user_tz":-120,"elapsed":506,"user":{"displayName":"Iker Silva Caballero","userId":"08949309632881622534"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"de195f39-4a5c-4073-ba9f-82059d7cfac3"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 200, 9]) torch.Size([200, 9]) torch.Size([200])\n","schizophrenia\n"]}],"source":["#ADHD\n","text_2= 'I am not sure if this is a sign that I am not sick or if I am just lazy and have no sense of direction.'\n","pred_2, _ = inference(text_2)\n","print(pred_2[0])"]},{"cell_type":"code","source":["model = MyModelDefinition(args)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","\n","checkpoint = torch.load('load/from/path/model.pth')\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","epoch = checkpoint['epoch']\n","loss = checkpoint['loss']\n"],"metadata":{"id":"jLpkfX3TcgNV"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"21a961e6a57b48bca7fbf892054b0eb7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f7764561fb8445b8a39229ded586b6c","IPY_MODEL_e7806248182f4e2caa9cf8ff5c034f93","IPY_MODEL_9fc1fd6ccf2746079a0446f2beb7254e"],"layout":"IPY_MODEL_b3fd4866ecb942449d8961fea43e4f94"}},"5f7764561fb8445b8a39229ded586b6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dd7fd83360d45a0bf19f75a1a140244","placeholder":"​","style":"IPY_MODEL_b221c5560eb9429d95e9524c47e755dd","value":"Map: 100%"}},"e7806248182f4e2caa9cf8ff5c034f93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7cedd7072ab4c49b84d5a1c927bd4b2","max":129600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e3fcc2f0bd64a4a8462b2170ea490d3","value":129600}},"9fc1fd6ccf2746079a0446f2beb7254e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba7c0844a7a6480eb5d2db8817fcf4a4","placeholder":"​","style":"IPY_MODEL_67edd10eef1f4938ae9a260bec02c3e2","value":" 129569/129600 [06:07&lt;00:00, 422.73 examples/s]"}},"b3fd4866ecb942449d8961fea43e4f94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"0dd7fd83360d45a0bf19f75a1a140244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b221c5560eb9429d95e9524c47e755dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7cedd7072ab4c49b84d5a1c927bd4b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e3fcc2f0bd64a4a8462b2170ea490d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba7c0844a7a6480eb5d2db8817fcf4a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67edd10eef1f4938ae9a260bec02c3e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee7770089fc44eaeb10bdf4db794a9d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_892c163accb84359b343687b276ba425","IPY_MODEL_ce4ae6cbc76d4ee2a5400bf1aa66f56a","IPY_MODEL_08b2ce73e42549af823274f29729e432"],"layout":"IPY_MODEL_b3f6cada52bd46b9a4d98d1c5af5424a"}},"892c163accb84359b343687b276ba425":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efe3d8da1c934bc190d5e8cb039b9562","placeholder":"​","style":"IPY_MODEL_0583353c5ec549869f9bcc9e591837c3","value":"Map: 100%"}},"ce4ae6cbc76d4ee2a5400bf1aa66f56a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_68f22214ecd048b092c6ef6b6c91bef6","max":14400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7133e40b2045404189000c6cd3265378","value":14400}},"08b2ce73e42549af823274f29729e432":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5e11399e4c948379b261a07b62a9a63","placeholder":"​","style":"IPY_MODEL_3f2c07327f284388b65b34fd830eddf3","value":" 14364/14400 [00:39&lt;00:00, 457.41 examples/s]"}},"b3f6cada52bd46b9a4d98d1c5af5424a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"efe3d8da1c934bc190d5e8cb039b9562":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0583353c5ec549869f9bcc9e591837c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68f22214ecd048b092c6ef6b6c91bef6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7133e40b2045404189000c6cd3265378":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5e11399e4c948379b261a07b62a9a63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f2c07327f284388b65b34fd830eddf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}